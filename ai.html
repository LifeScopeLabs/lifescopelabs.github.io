<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>lifescope-ai</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__left">
    <div class="stackedit__toc">
      
<ul>
<li><a href="#lifescope-ai">LIFESCOPE-AI</a>
<ul>
<li><a href="#repository">Repository</a></li>
</ul>
</li>
<li><a href="#reporting-concept-phase-low-priority">Reporting (concept phase, low priority)</a>
<ul>
<li></li>
</ul>
</li>
<li><a href="#machine-learning-concept-phase-low-priority">Machine Learning (concept phase, low priority)</a>
<ul>
<li><a href="#conversational-agents">Conversational Agents</a></li>
<li><a href="#geolocation-based-models">Geolocation Based Models</a>
<ul>
<li></li>
<li><a href="#proposed-technology-and-examples-2">Proposed Technology and Examples</a></li>
<li><a href="#others-tensorflow">Others (Tensorflow)</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
  </div>
  <div class="stackedit__right">
    <div class="stackedit__html">
      <h1 id="lifescope-ai"><a href="https://github.com/LifeScopeLabs/lifescope-ai">LIFESCOPE-AI</a></h1>
<h2 id="repository"><a href="https://github.com/LifeScopeLabs/lifescope-ai">Repository</a></h2>
<p>This repository contains a suite of tools for reporting and machine learning workflow from LIFESCOPE data. Reporting is focused on building approachable dashboard visualizations and infographics.</p>
<p>Machine learning models based on LIFESCOPE data are currently focused on behavior modeling, correlation, prediction, suggestion, and impersonation.</p>
<h1 id="reporting-concept-phase-low-priority">Reporting (concept phase, low priority)</h1>
<p>Create infographics and reports for LIFESCOPE users based on their data. Personal Infographic Examples:</p>
<p>Finance Overview Bubble Chart {Merchants x Item Count x Total Price]<br>
Social Overview Line Chart [Social platform (Twitter, Linked In, Facebook) x Mentions &amp; Likes x Time ]<br>
<img src="https://lifescopelabs.github.io/assets/screenshots/infographics1.png" alt="infographics1"></p>
<p>Time Vertical Gantt Chart [Week x Event Type]<br>
Messaging Bar Chart [% to vs From]<br>
<img src="https://lifescopelabs.github.io/assets/screenshots/infographics2.png" alt="infographics2"></p>
<p>Heatmap of activity<br>
<img src="https://lifescopelabs.github.io/assets/maps/heat-map.png" alt="heatmap"></p>
<p>Network Visualizations of Deep Learning Training<br>
<img src="https://lifescopelabs.github.io/assets/wireframes/DeepLearningViz.png" alt="deepviz"></p>
<h3 id="proposed-technology-and-examples">Proposed Technology and Examples</h3>
<ul>
<li><a href="https://www.taucharts.com/">Tau Charts</a></li>
</ul>
<h1 id="machine-learning-concept-phase-low-priority">Machine Learning (concept phase, low priority)</h1>
<h2 id="conversational-agents">Conversational Agents</h2>
<p>Impersonation Ideas:</p>
<ul>
<li><strong>Persona-based model</strong>. Condition responses on a certain author of messages (User ID) to make responses lexically similar to them and mimic someone’s linguistic style in a conversation. Use new or pre-trained models to run a chatbot that maintains a conversation in a certain emotional state.</li>
<li><strong>Emotional chatting machine</strong> with your own set of emotions. There are so many emotions that you can use as condition labels in your dataset. CakeChat only uses five basic emotions (anger, sadness, joy, fear and neutral).</li>
<li><strong>Topic-centric model</strong>. Instead of emotions, you can use a set of topics that will condition the model’s responses. As a result, you can build an agent that sticks to a given topic in a conversation. For example, you can build a model that talks about weather, food, kids or mortgage at any given moment.</li>
</ul>
<h3 id="proposed-technology-and-examples-1">Proposed Technology and Examples</h3>
<ul>
<li><a href="https://cakechat.replika.ai/">CakeChat Framework</a></li>
</ul>
<h2 id="geolocation-based-models">Geolocation Based Models</h2>
<p><img src="https://raw.githubusercontent.com/numenta/nupic.geospatial/master/images/viewer.png" alt="mlgeo"></p>
<p>Prediction and anomaly detection based on location history.</p>
<h4 id="using-the-nupic-geospatial-tracking-application"><a href="http://www.youtube.com/watch?v=M4dD9wCQLkA">Using the NuPIC Geospatial Tracking Application</a></h4>
<p><a href="http://www.youtube.com/watch?v=M4dD9wCQLkA"><img src="http://img.youtube.com/vi/M4dD9wCQLkA/hqdefault.jpg" alt="NuPIC Geospatial Tracking Application Tutorial"></a></p>
<h4 id="geospatial-coordinate-encoder-explained"><a href="http://www.youtube.com/watch?v=KxxHo-FtKRo">Geospatial Coordinate Encoder Explained</a></h4>
<p><a href="http://www.youtube.com/watch?v=KxxHo-FtKRo"><img src="http://img.youtube.com/vi/KxxHo-FtKRo/hqdefault.jpg" alt="Geospatial Coordinate Encoder"></a></p>
<h3 id="proposed-technology-and-examples-2">Proposed Technology and Examples</h3>
<ul>
<li><a href="https://numenta.com/assets/pdf/whitepapers/Geospatial%20Tracking%20White%20Paper.pdf">Numenta Geospatioal</a></li>
<li><a href="https://github.com/numenta/nupic.geospatial">Numenta Geospatioal Github Example</a></li>
</ul>
<h3 id="others-tensorflow">Others (Tensorflow)</h3>
<ul>
<li><a href="https://github.com/tensorflow/models/tree/master/research">Tenorflow Research Models for (Speech, Text, Video, Geodata</a></li>
</ul>

    </div>
  </div>
</body>

</html>
